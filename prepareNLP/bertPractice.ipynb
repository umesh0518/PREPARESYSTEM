{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d40b889-19b4-48f1-9b37-a981aadc50c5",
   "metadata": {},
   "source": [
    "<h4>Note : BERT base has 12 encoders and BERT Large has 24 encoder.</h4> <h5>We will be using BERT base with 12 encoders </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611bf144-d081-49a3-8819-4aea940b493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abac8547-804b-4ed7-9d54-67b24aa54519",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181fc3b-e666-4dd4-a663-149d3c59bd75",
   "metadata": {},
   "source": [
    "<h4> We will 1st create a preprocessing layer, for preprocessing our text </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947db417-0450-483b-ac65-19ea4fbfa38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For preprocessing. We can supply bunch of statements, and it will do preprocessing.\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46be7a30-2b6e-4ff4-a101-138dfc3e5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = ['nice movie indeed','I love python programming']\n",
    "text_preprocessed = bert_preprocess_model(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7264c3b-7534-46ab-929e-81fe9fbd3c3b",
   "metadata": {},
   "source": [
    "<p>This will return dictionary with <b>input_mask </b>, <b>input_type_ids</b>, and <b>input_word_ids</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ca7db9-8da6-4805-b116-9371ab60049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_type_ids', 'input_mask', 'input_word_ids'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b64c97-4795-4763-8d22-4e8fe741ced9",
   "metadata": {},
   "source": [
    "<h4>input_mask</h4>\n",
    "<p>It is of shape (2,128). 2 is no of sentence, and 128 length of text.</p>\n",
    "Note : For 1st sentence there are 5 1's. It treats 1st sentence as <b>CLS nice movie indeed SEP </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33299ce6-28c1-498e-b640-50c2a17d4757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f10d9a-637b-4d4d-82b1-f1e682ed1846",
   "metadata": {},
   "source": [
    "<h4>input_type_ids</h4>\n",
    "<p>It is also of shape (2,128). 2 is no of sentence, and 128 length of text.</p>\n",
    "They are useful when you have multiple sentence in one statement. For our case, all value will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62be1b8d-a516-42b1-b515-f9c2902ff8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_type_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60819b4-3880-448f-86d4-2b215beaeb94",
   "metadata": {},
   "source": [
    "<h4>input_word_ids</h4>\n",
    "<p>It is also of shape (2,128). 2 is no of sentence, and 128 length of text.</p>\n",
    "It indicates word id of each word in sentence. For first sentence, <b>word_id of CLS = 101, nice = 3835, movie = 3185, indeed = 5262, SEP = 102 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a94d792-b14c-46d7-bcc9-92081fc0707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[  101,  3835,  3185,  5262,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  1045,  2293, 18750,  4730,   102,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed['input_word_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc600dc8-825d-4f7c-88d8-5c515d822712",
   "metadata": {},
   "source": [
    "<h4> Now the preprocessing is done. We can create encoding layer.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d142fcc-0719-414f-b65e-fb21d12f8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f3ae6-978d-4d6d-bef6-64fd70edbba3",
   "metadata": {},
   "source": [
    "<h5>We can supply pre processed text to this encoding layer. This encoding layer will generate sentence or word embeddings. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab42403-bb22-4d63-8cd4-6a5134a144ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_results = bert_model(text_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588ccf1-a438-4fa4-be7d-4042562cd979",
   "metadata": {},
   "source": [
    "This will return dictionary with 3 keys. <b>encoder_outputs, pooled_output, sequence_output</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d02415-5c0f-481c-9973-b972478fc6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['default', 'pooled_output', 'encoder_outputs', 'sequence_output'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe1a1d-5817-43da-bfa7-2e71b8e044dd",
   "metadata": {},
   "source": [
    "<h4>pooled_output</h4>\n",
    "<b>pooled_output</b> is an embedding for entire sentence. The resulting tensor will be of shape <b>(2,768) </b>.Here 2 is no of sentence and <b>768</b> is dimesnion of embedding. This each 768 vector accurately represent each statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8d0594-4021-485f-93c2-5bf85d27e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.79177445, -0.21411942,  0.49769488, ...,  0.24465126,\n",
       "        -0.47334498,  0.8175873 ],\n",
       "       [-0.9171231 , -0.4793517 , -0.78656983, ..., -0.6175176 ,\n",
       "        -0.7102685 ,  0.92184293]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['pooled_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26315d-b161-4be5-bba5-fd6dfc3a77f2",
   "metadata": {},
   "source": [
    "<h4>sequence_output</h4>\n",
    "<b>sequence_output</b> is individual word embedding vectors. <b>Note: For each word inside sentence, it was 768 size word embedding vector</b>.\n",
    "Hence, the shape of tensor is <b>(2,128,768)</b> . Here, <b>2 = no of sentence </b>, <b>128 = no of words in each sentence </b>,and  <b>768 = word embedding for each word in sentence </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8dd624a-95c1-4835-b361-b4d33b16fbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.07292067,  0.08567819,  0.14476839, ..., -0.09677105,\n",
       "          0.08722159,  0.07711076],\n",
       "        [ 0.17839423, -0.19006088,  0.5034951 , ..., -0.05869836,\n",
       "          0.32717168, -0.15578607],\n",
       "        [ 0.18701434, -0.43388814, -0.48875174, ..., -0.15502723,\n",
       "          0.00145242, -0.24470958],\n",
       "        ...,\n",
       "        [ 0.12083033,  0.12884216,  0.4645349 , ...,  0.07375568,\n",
       "          0.17441967,  0.16522148],\n",
       "        [ 0.07967912, -0.01190673,  0.50225425, ...,  0.13777754,\n",
       "          0.21002257,  0.00624568],\n",
       "        [-0.07212678, -0.28303456,  0.5903342 , ...,  0.4755191 ,\n",
       "          0.16668472, -0.08920309]],\n",
       "\n",
       "       [[-0.07900576,  0.36335146, -0.21101616, ..., -0.17183737,\n",
       "          0.16299757,  0.6724266 ],\n",
       "        [ 0.2788348 ,  0.4371632 , -0.35764787, ..., -0.04463551,\n",
       "          0.3831522 ,  0.5887987 ],\n",
       "        [ 1.2037671 ,  1.0727023 ,  0.4840871 , ...,  0.24921003,\n",
       "          0.40730935,  0.40481764],\n",
       "        ...,\n",
       "        [ 0.08630074,  0.1935386 ,  0.4754004 , ...,  0.18880151,\n",
       "         -0.06474096,  0.31318578],\n",
       "        [ 0.15887073,  0.285727  ,  0.37340778, ...,  0.09309137,\n",
       "         -0.04969543,  0.38761094],\n",
       "        [-0.08079866, -0.09572858,  0.26809746, ...,  0.13979612,\n",
       "         -0.06315832,  0.27288306]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['sequence_output'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930495a-a2d9-48da-886c-816f218ef980",
   "metadata": {},
   "source": [
    "<h4>encoder_outputs</h4>.\n",
    "If we look at length of encoder output, it is <b>12</b>. Because, we are using BERT with 12 encoder. And each layer has 768 size embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31093aa-a2e7-4477-ae3d-4b96a8fb5f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_results['encoder_outputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e14ccc4-ead3-4477-92f3-cddaa49ad1b4",
   "metadata": {},
   "source": [
    "<p> Each of these <b>encoder_ouputs </b> will be <b>(2,128,768)</b> size vector.  Here, <b>2 = no of sentence </b>, <b>128 = no of words in each sentence </b>,and  <b>768 = word embedding for each word in sentence </b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b95504-a6e3-471c-8031-6f451875e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.12901412,  0.00644755, -0.03614965, ...,  0.04999633,\n",
       "          0.06149195, -0.02657555],\n",
       "        [ 1.1753379 ,  1.2140787 ,  1.1569977 , ...,  0.11634361,\n",
       "         -0.35855392, -0.40490174],\n",
       "        [ 0.03859011,  0.53869987, -0.21089745, ...,  0.21858183,\n",
       "          0.72601724, -1.1158607 ],\n",
       "        ...,\n",
       "        [-0.07587045, -0.2542191 ,  0.7075512 , ...,  0.50542   ,\n",
       "         -0.18878683,  0.15028355],\n",
       "        [-0.160666  , -0.28089684,  0.57597065, ...,  0.52758557,\n",
       "         -0.1114136 ,  0.02887519],\n",
       "        [-0.04428155, -0.20279573,  0.59093577, ...,  0.8133834 ,\n",
       "         -0.390758  , -0.02601733]],\n",
       "\n",
       "       [[ 0.18903567,  0.02752543, -0.06513736, ..., -0.0062021 ,\n",
       "          0.15053876,  0.03165446],\n",
       "        [ 0.5916145 ,  0.75891393, -0.07240694, ...,  0.61903995,\n",
       "          0.829289  ,  0.1616199 ],\n",
       "        [ 1.4460828 ,  0.4460268 ,  0.40990224, ...,  0.4825589 ,\n",
       "          0.6269117 ,  0.13463363],\n",
       "        ...,\n",
       "        [ 0.15147913, -0.21573833,  0.70329076, ..., -0.12537211,\n",
       "         -0.13787216,  0.2772208 ],\n",
       "        [ 0.05143805, -0.24052693,  0.53569174, ..., -0.07914999,\n",
       "         -0.03307918,  0.17380935],\n",
       "        [ 0.20934698, -0.15645263,  0.6039548 , ...,  0.32903498,\n",
       "         -0.35827175,  0.08100444]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['encoder_outputs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5191f7-9c38-4524-890e-d10b31eb6668",
   "metadata": {},
   "source": [
    "The last encoding layer vector is same as the <b>sequence _output</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5cb1cb-aade-46b4-8a14-228dfc6706cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.07292067,  0.08567819,  0.14476839, ..., -0.09677105,\n",
       "          0.08722159,  0.07711076],\n",
       "        [ 0.17839423, -0.19006088,  0.5034951 , ..., -0.05869836,\n",
       "          0.32717168, -0.15578607],\n",
       "        [ 0.18701434, -0.43388814, -0.48875174, ..., -0.15502723,\n",
       "          0.00145242, -0.24470958],\n",
       "        ...,\n",
       "        [ 0.12083033,  0.12884216,  0.4645349 , ...,  0.07375568,\n",
       "          0.17441967,  0.16522148],\n",
       "        [ 0.07967912, -0.01190673,  0.50225425, ...,  0.13777754,\n",
       "          0.21002257,  0.00624568],\n",
       "        [-0.07212678, -0.28303456,  0.5903342 , ...,  0.4755191 ,\n",
       "          0.16668472, -0.08920309]],\n",
       "\n",
       "       [[-0.07900576,  0.36335146, -0.21101616, ..., -0.17183737,\n",
       "          0.16299757,  0.6724266 ],\n",
       "        [ 0.2788348 ,  0.4371632 , -0.35764787, ..., -0.04463551,\n",
       "          0.3831522 ,  0.5887987 ],\n",
       "        [ 1.2037671 ,  1.0727023 ,  0.4840871 , ...,  0.24921003,\n",
       "          0.40730935,  0.40481764],\n",
       "        ...,\n",
       "        [ 0.08630074,  0.1935386 ,  0.4754004 , ...,  0.18880151,\n",
       "         -0.06474096,  0.31318578],\n",
       "        [ 0.15887073,  0.285727  ,  0.37340778, ...,  0.09309137,\n",
       "         -0.04969543,  0.38761094],\n",
       "        [-0.08079866, -0.09572858,  0.26809746, ...,  0.13979612,\n",
       "         -0.06315832,  0.27288306]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['encoder_outputs'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e04eb8-b1bd-487e-b6e5-3a3b3703baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results['encoder_outputs'][-1] == bert_results['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ffaea8-360c-464b-842d-fb25dff5154a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffd840-e978-4439-9f20-2e71d5908170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dccaf964-1dd8-4b50-81c7-0b157fe6b92c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Build a model using BERT </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa7b91d6-9b07-4129-9307-0837eac0401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63ed6e2a-2b8f-4dee-a322-221c35de74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947175b-9b40-4926-b6c4-382332016d79",
   "metadata": {},
   "source": [
    "<h3> Only updating Dense Layer. Freezing BERT Layer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed5e2ca9-cb44-4925-b057-f360698ed2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef6221a1-11aa-4829-964f-e41b6bf87f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_2 (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_3 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_2[0][0]',          \n",
      "                                None, 768),                       'keras_layer_2[0][1]',          \n",
      "                                 'encoder_outputs':               'keras_layer_2[0][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_3[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a573c08-127a-40e0-b3ef-44182bc932a3",
   "metadata": {},
   "source": [
    "<h3> Updating both Bert layer and Dense Layer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b972932a-9719-4856-a273-b84241a71db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "bert_encoder.trainable = True  # Set the trainable attribute of the BERT layer to True. It is false by default\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5866fc77-1a6b-419d-8050-030455bed5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_2 (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_3 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_2[1][0]',          \n",
      "                                None, 768),                       'keras_layer_2[1][1]',          \n",
      "                                 'encoder_outputs':               'keras_layer_2[1][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_3[1][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a06f27-2774-4de5-b477-98d1155d3485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spappad\\AppData\\Local\\miniconda3\\envs\\prepareNLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21204564-245a-4935-9ba4-04498397d00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277f20e6-3475-45b4-aacc-25607320bc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71485d1a-bd81-44eb-9327-68d969bb9e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95fbea4-54ab-4068-8e92-36bcd18e9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\spappad\\AppData\\Local\\Temp\\3\\ipykernel_8944\\2658560566.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "# Check if GPU is available\n",
    "if tensorflow.test.is_gpu_available():\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db436a3e-157d-48fd-b077-8db858331a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get a list of available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Check if any GPUs are available\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f'GPU: {gpu.name}')\n",
    "else:\n",
    "    print('No GPUs detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6010703a-97ca-4f0e-b7e1-c31fb584d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only = False, min_cuda_compute_capability = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f0ca14-b97b-4c4d-a808-c6a6b75b31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc3331-76fd-4ca6-b191-687395231e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d7e28-4514-4da5-8593-9ff61c4d9d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
